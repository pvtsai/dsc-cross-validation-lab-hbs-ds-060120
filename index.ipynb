{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Cross-Validation - Lab\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this lab, you'll be able to practice your cross-validation skills!\n",
    "\n",
    "\n",
    "## Objectives\n",
    "\n",
    "You will be able to:\n",
    "\n",
    "- Perform cross validation on a model to determine optimal model performance\n",
    "- Compare training and testing errors to determine if model is over or underfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's get started\n",
    "\n",
    "We included the code to pre-process below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "ames = pd.read_csv('ames.csv')\n",
    "\n",
    "continuous = ['LotArea', '1stFlrSF', 'GrLivArea', 'SalePrice']\n",
    "categoricals = ['BldgType', 'KitchenQual', 'SaleType', 'MSZoning', 'Street', 'Neighborhood']\n",
    "\n",
    "ames_cont = ames[continuous]\n",
    "\n",
    "# log features\n",
    "log_names = [f'{column}_log' for column in ames_cont.columns]\n",
    "\n",
    "ames_log = np.log(ames_cont)\n",
    "ames_log.columns = log_names\n",
    "\n",
    "# normalize (subract mean and divide by std)\n",
    "\n",
    "def normalize(feature):\n",
    "    return (feature - feature.mean()) / feature.std()\n",
    "\n",
    "ames_log_norm = ames_log.apply(normalize)\n",
    "\n",
    "# one hot encode categoricals\n",
    "ames_ohe = pd.get_dummies(ames[categoricals], prefix=categoricals, drop_first=True)\n",
    "\n",
    "preprocessed = pd.concat([ames_log_norm, ames_ohe], axis=1)\n",
    "\n",
    "X = preprocessed.drop('SalePrice_log', axis=1)\n",
    "y = preprocessed['SalePrice_log']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-test split\n",
    "\n",
    "Perform a train-test split with a test set of 20%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import train_test_split from sklearn.model_selection\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets (assign 20% to test set)\n",
    "num = 20\n",
    "train_err = []\n",
    "test_err = []\n",
    "for i in range(num):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1168 292 1168 292\n"
     ]
    }
   ],
   "source": [
    "# A brief preview of train-test split\n",
    "print(len(X_train), len(X_test), len(y_train), len(y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit a linear regression model and apply the model to make predictions on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "from sklearn.linear_model import LinearRegression\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_train = linreg.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.03517942,  1.5263714 ,  0.90613963, ..., -0.28751344,\n",
       "        0.66782072, -0.06178604])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5.16367548e-01, -5.13951044e-01, -6.77990953e-01, -2.08526813e+00,\n",
       "        3.63600141e-01,  4.69326069e-01, -1.20181620e+00,  8.27742044e-01,\n",
       "       -3.86859896e-01,  6.36449593e-01, -6.33753709e-01,  1.33515284e+00,\n",
       "       -4.33768341e-01,  8.34049583e-01, -8.54392393e-01, -3.23328344e-01,\n",
       "        1.24809992e+00, -9.07038934e-02, -3.09789133e-01,  1.59582107e+00,\n",
       "        1.58135490e+00,  8.08201687e-01,  2.01108255e+00,  2.53028093e+00,\n",
       "       -7.05012494e-02, -1.36369381e+00,  2.23591078e+00, -1.96873552e-01,\n",
       "        1.34694164e-01,  2.20535457e+00,  9.05923401e-01, -7.69472849e-02,\n",
       "        8.53561917e-01, -6.69163490e-01, -6.61754018e-01, -1.00009035e+00,\n",
       "        7.66594587e-01,  6.04686740e-01, -8.85630511e-02, -7.41343113e-01,\n",
       "       -1.13598253e+00, -1.11324941e-02, -5.92103178e-01, -1.47068480e+00,\n",
       "       -2.78318146e-01, -5.49434262e-01, -6.80513519e-01, -6.26327398e-01,\n",
       "       -3.70696600e-01,  5.15173038e-01, -4.66726950e-01, -5.60151307e-01,\n",
       "       -3.40750304e-01,  6.22437145e-01,  5.38387952e-01, -1.26326400e+00,\n",
       "        1.16977748e-01, -7.82073111e-01, -7.33155656e-01, -4.68495059e-01,\n",
       "        2.02437789e-01, -6.71415669e-01,  7.97996992e-01,  8.47038172e-01,\n",
       "        4.42541415e-01, -6.41421184e-01, -1.85093869e-01,  8.47114776e-01,\n",
       "        1.06942160e+00, -1.17734050e-01,  6.06907361e-01,  2.14045293e-01,\n",
       "        1.00596081e-01, -8.11946202e-01,  1.53628117e-01, -9.42476391e-02,\n",
       "       -2.51387947e-01, -1.12045359e+00, -3.17056871e-01, -1.01950351e+00,\n",
       "       -4.36320603e-01,  1.93987673e-01,  6.83464386e-01,  5.32963135e-01,\n",
       "       -2.71277427e-01,  6.91959498e-01, -2.40297435e-01, -9.01070732e-01,\n",
       "       -7.27406791e-01, -2.74352777e+00, -1.84148377e+00,  2.26792377e+00,\n",
       "        2.08705055e+00,  9.15993053e-02,  9.95793027e-01,  6.01144783e-01,\n",
       "       -1.18943189e+00, -1.25391278e+00, -9.41973675e-01,  1.17348216e+00,\n",
       "       -1.15428622e+00,  7.04887916e-01, -7.10077822e-01, -2.10926489e+00,\n",
       "        2.08592461e+00,  1.03637123e+00,  3.99008299e-01,  6.06435066e-01,\n",
       "       -9.13099491e-01, -1.81977638e-01,  8.65652978e-01, -5.70181538e-01,\n",
       "        1.44189879e+00,  1.51865990e+00, -4.19660781e-02,  8.22239457e-01,\n",
       "       -2.30416879e-01,  1.50267288e+00, -7.20786861e-01, -1.38388047e-01,\n",
       "        3.16464492e-01,  6.90692316e-01, -1.72970792e-01,  1.57837488e+00,\n",
       "       -8.59889476e-01, -1.05431634e-01, -2.73133302e-01, -5.36591114e-01,\n",
       "       -5.93383018e-01,  1.37053172e+00,  1.46903193e+00,  4.97501454e-01,\n",
       "        3.18904211e-01,  1.83991743e-01,  3.55966473e-01, -1.04342454e-01,\n",
       "        9.87950124e-01,  1.36034549e+00,  2.47956699e+00, -3.45903018e-01,\n",
       "        1.34699399e+00,  3.71413228e-01,  6.23667559e-01, -6.64182816e-01,\n",
       "       -1.17180296e+00,  3.94824197e-02,  1.35570250e-02, -7.65839835e-01,\n",
       "        9.61824107e-01,  5.73066344e-01, -4.01250634e-01,  3.40370854e-01,\n",
       "       -5.54123033e-01,  1.98599828e+00, -3.83784576e-01,  8.99262966e-01,\n",
       "        6.47399814e-01,  2.28435845e-01,  4.34423281e-01, -1.68331567e+00,\n",
       "        9.86529424e-01, -2.06560439e-01, -7.15814330e-01, -1.09012192e+00,\n",
       "       -2.52704500e-03,  5.67433080e-01, -4.93383410e-01,  5.31404224e-01,\n",
       "        1.32750864e+00, -1.17830791e+00, -3.01153269e-01,  1.11679762e+00,\n",
       "       -2.07742461e+00, -4.40342809e-01, -1.63918210e-01,  4.10647530e-01,\n",
       "       -5.85500365e-01,  2.75463123e+00,  5.15738499e-02,  1.23652471e+00,\n",
       "       -7.90262283e-01,  6.13168831e-01, -5.56755767e-01, -6.16540349e-02,\n",
       "       -8.42959691e-01,  2.19130129e+00, -2.22213945e-01,  1.37432988e+00,\n",
       "        3.67342271e-01,  6.61824160e-01, -1.31321310e+00,  1.36874308e+00,\n",
       "       -1.55982968e+00, -1.55003510e+00, -4.18200953e-01, -3.88225989e-01,\n",
       "        8.73921313e-01, -5.80878135e-01, -9.26534534e-01,  5.33282926e-01,\n",
       "        2.45951650e-01, -9.77139321e-01,  5.12941917e-01, -1.41966421e+00,\n",
       "       -7.09819870e-01,  3.18848525e-01,  6.59436241e-01,  1.73997417e-01,\n",
       "       -1.79691659e-02, -7.86596387e-01, -3.35787709e-01, -1.67740975e-01,\n",
       "        4.12857561e-01, -6.60496911e-01, -3.98425685e-01, -7.75367296e-01,\n",
       "       -5.34059433e-01,  2.17583067e+00, -9.39507996e-01,  1.42024648e+00,\n",
       "        7.40252512e-01,  2.53257150e-01, -4.00446449e-01, -3.49178466e-01,\n",
       "        2.91404373e-01,  4.47698191e-01, -3.49853843e-01, -1.03648062e+00,\n",
       "        7.68251266e-01,  6.11173409e-01,  1.48884805e-01,  3.47910520e-01,\n",
       "       -8.45053263e-01, -7.08558639e-01,  3.08349187e-01,  1.70658166e-01,\n",
       "       -8.31542540e-01,  1.92471802e+00, -1.61153106e-01,  8.88959358e-01,\n",
       "        1.75943566e+00, -1.25599358e+00, -5.48004248e-01, -1.44530658e+00,\n",
       "       -7.92941438e-01, -7.98223491e-01,  1.75302296e+00, -1.44596955e+00,\n",
       "        7.91673326e-01,  5.19784154e-01, -6.37139420e-01, -5.70008150e-01,\n",
       "        3.49009093e-01,  6.75217276e-01,  2.69970218e-01, -6.33002161e-01,\n",
       "       -3.49244114e-01,  6.36503426e-01,  2.31665580e+00, -9.79604319e-01,\n",
       "        1.42158802e+00,  9.36854347e-02, -1.36759739e-02,  1.52165019e+00,\n",
       "       -5.76507263e-02,  8.25932952e-01,  5.55291984e-01,  3.63206309e-01,\n",
       "        3.35794612e-01, -4.68234805e-01, -1.66814873e+00,  6.06478228e-01,\n",
       "       -1.54650239e+00, -8.81778054e-01,  9.83832941e-01,  7.92525732e-01,\n",
       "        2.17152163e-01,  8.32650838e-01, -7.03106062e-01, -5.78399592e-01,\n",
       "       -8.14246672e-01,  1.06394896e+00, -9.51029866e-01, -3.82549482e-01,\n",
       "       -4.71477086e-01, -9.80888377e-01,  7.37018278e-01, -6.17842949e-02,\n",
       "        1.55323857e-01, -5.78117099e-01,  6.38247367e-01,  9.07665306e-01])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat_test = linreg.predict(X_test)\n",
    "y_hat_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Residuals and MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the residuals and the mean squared error on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21518632306958718"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "from sklearn.metrics import mean_squared_error\n",
    "test_residuals = y_hat_test - y_test\n",
    "\n",
    "test_mse = mean_squared_error(y_test, y_hat_test)\n",
    "test_mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validation: let's build it from scratch!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a cross-validation function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function `kfolds()` that splits a dataset into k evenly sized pieces. If the full dataset is not divisible by k, make the first few folds one larger then later ones.\n",
    "\n",
    "We want the folds to be a list of subsets of data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfolds(data, k):\n",
    "    # Force data as pandas DataFrame\n",
    "    # add 1 to fold size to account for leftovers           \n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply it to the Ames Housing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure to concatenate the data again\n",
    "ames_data = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply kfolds() to ames_data with 5 folds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform a linear regression for each fold and calculate the training and test error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform linear regression on each and calculate the training and test error: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_errs = []\n",
    "train_errs = []\n",
    "k=5\n",
    "\n",
    "for n in range(k):\n",
    "    # Split in train and test for the fold\n",
    "    train = None\n",
    "    test = None\n",
    "    # Fit a linear regression model\n",
    "    \n",
    "    # Evaluate Train and Test errors\n",
    "\n",
    "# print(train_errs)\n",
    "# print(test_errs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validation using Scikit-Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was a bit of work! Now, let's perform 5-fold cross-validation to get the mean squared error through scikit-learn. Let's have a look at the five individual MSEs and explain what's going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, calculate the mean of the MSE over the 5 cross-validation and compare and contrast with the result from the train-test split case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Summary "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! You are now familiar with cross-validation and know how to use `cross_val_score()`. Remember that the results obtained from cross-validation are robust and always use it whenever possible! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
